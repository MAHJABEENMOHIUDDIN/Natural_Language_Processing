{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import classification_report,accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>I thought this movie did a down right good job...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>Bad plot, bad dialogue, bad acting, idiotic di...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>I am a Catholic taught in parochial elementary...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>I'm going to have to disagree with the previou...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>No one expects the Star Trek movies to be high...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment\n",
       "0      One of the other reviewers has mentioned that ...  positive\n",
       "1      A wonderful little production. <br /><br />The...  positive\n",
       "2      I thought this was a wonderful way to spend ti...  positive\n",
       "3      Basically there's a family where a little boy ...  negative\n",
       "4      Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
       "...                                                  ...       ...\n",
       "49995  I thought this movie did a down right good job...  positive\n",
       "49996  Bad plot, bad dialogue, bad acting, idiotic di...  negative\n",
       "49997  I am a Catholic taught in parochial elementary...  negative\n",
       "49998  I'm going to have to disagree with the previou...  negative\n",
       "49999  No one expects the Star Trek movies to be high...  negative\n",
       "\n",
       "[50000 rows x 2 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imbd_movie_review = pd.read_csv(\"/Volumes/DriveB/NLP_Learning/Movie Review Prediction/IMDB Dataset.csv\")\n",
    "imbd_movie_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        1\n",
       "1        1\n",
       "2        1\n",
       "3        0\n",
       "4        1\n",
       "        ..\n",
       "49995    1\n",
       "49996    0\n",
       "49997    0\n",
       "49998    0\n",
       "49999    0\n",
       "Name: sentiment, Length: 50000, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imbd_movie_review['sentiment'] = imbd_movie_review['sentiment'].map({'negative':0,'positive': 1})\n",
    "imbd_movie_review['sentiment'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/mahjabeenmohiuddin/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/mahjabeenmohiuddin/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/mahjabeenmohiuddin/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "#Downloading necessary nltk data\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "\n",
    "\n",
    "#Initializing thre lemitizer and stop words\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text): \n",
    "    if isinstance(text, str): \n",
    "      text = text.lower()\n",
    "      text = re.sub(pattern = '[^a-zA-Z]', repl = ' ', string =text)\n",
    "      text = re.sub(pattern= '\\s+', repl = ' ', string= text).strip()\n",
    "      text = re.sub(r'[  \\t]+$', '', text)  \n",
    "      cleaned_tokens = [lemmatizer.lemmatize(word) for word in words if word not in stop_words]\n",
    "\n",
    "      cleaned_text = ' '.join(cleaned_tokens)\n",
    "      return cleaned_text\n",
    "    else:\n",
    "       return \"\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              review  \\\n",
      "0  One of the other reviewers has mentioned that ...   \n",
      "1  A wonderful little production. <br /><br />The...   \n",
      "2  I thought this was a wonderful way to spend ti...   \n",
      "3  Basically there's a family where a little boy ...   \n",
      "4  Petter Mattei's \"Love in the Time of Money\" is...   \n",
      "\n",
      "                                      cleaned_review  \n",
      "0  one reviewer mentioned watching oz episode hoo...  \n",
      "1  wonderful little production br br filming tech...  \n",
      "2  thought wonderful way spend time hot summer we...  \n",
      "3  basically family little boy jake think zombie ...  \n",
      "4  petter mattei love time money visually stunnin...  \n"
     ]
    }
   ],
   "source": [
    "imbd_movie_review['cleaned_review'] = imbd_movie_review['review'].apply(clean_text)\n",
    "\n",
    "\n",
    "print(imbd_movie_review[['review', 'cleaned_review']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "review            0\n",
       "sentiment         0\n",
       "cleaned_review    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imbd_movie_review.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<50000x5000 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 3986304 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X = vectorizer.fit_transform(imbd_movie_review['cleaned_review'])\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        1\n",
       "1        1\n",
       "2        1\n",
       "3        0\n",
       "4        1\n",
       "        ..\n",
       "49995    1\n",
       "49996    0\n",
       "49997    0\n",
       "49998    0\n",
       "49999    0\n",
       "Name: sentiment, Length: 50000, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = imbd_movie_review['sentiment']\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting the data into train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dimension of X_train is: (40000, 5000)\n",
      "The dimension of X_test is: (10000, 5000)\n",
      "The dimension of y_train is: (40000,)\n",
      "The dimension of y_test is: (10000,)\n"
     ]
    }
   ],
   "source": [
    "print(\"The dimension of X_train is:\", X_train.shape)\n",
    "print(\"The dimension of X_test is:\", X_test.shape)\n",
    "print(\"The dimension of y_train is:\", y_train.shape)\n",
    "print(\"The dimension of y_test is:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiation of class and Training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(random_state=42)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rfc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score, precision, recall,f1-score,  and support scores of training set are:\n",
      "\n",
      "The accuracy score is:, 1.0000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    positive       1.00      1.00      1.00     20039\n",
      "    negative       1.00      1.00      1.00     19961\n",
      "\n",
      "    accuracy                           1.00     40000\n",
      "   macro avg       1.00      1.00      1.00     40000\n",
      "weighted avg       1.00      1.00      1.00     40000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_predict = rfc.predict(X_train)\n",
    "print(\"The accuracy score, precision, recall,f1-score,  and support scores of training set are:\\n\")\n",
    "print(f\"The accuracy score is:, {accuracy_score(y_train_, train_predict_):.4f}\")\n",
    "print(f\"{classification_report(y_train_, train_predict_, target_names=['positive', 'negative'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score, precision, recall, f1-score, and support scores of test set are:\n",
      "\n",
      "The accuracy score is:, 0.8524\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Positive       0.84      0.86      0.85      4961\n",
      "    Negative       0.86      0.84      0.85      5039\n",
      "\n",
      "    accuracy                           0.85     10000\n",
      "   macro avg       0.85      0.85      0.85     10000\n",
      "weighted avg       0.85      0.85      0.85     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_predict = rfc.predict(X_test)\n",
    "print(\"The accuracy score, precision, recall, f1-score, and support scores of test set are:\\n\")\n",
    "print(f\"The accuracy score is:, {accuracy_score(y_test_,test_predict_):.4f}\")\n",
    "print(f\"{classification_report(y_test_, test_predict_, target_names = ['Positive', 'Negative'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result of Trained model is that model is overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the model on prediction of sample revies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 1:\n",
      "Review: gifted succeeds demon imagined cruel ben miserable theatre necessarily joan ambitious overly sleazy released producer often obnoxious flaw supporting husband figure obviously throughout edge without opening alone unlike directed drunk tough fascinating want part actress night although john especially someone except could quite take self secret long early try least also almost let sure role eye performance last good stage director seems stunning playing real film make fighting woman love fully character dialogue way life see truly actor give time production well developed around would never go word\n",
      "True Label: Positive\n",
      "Predicted Label: Positive\n",
      "Match: True\n",
      "\n",
      "Sample 2:\n",
      "Review: needle remotely contemporary passionate interested martin american moment general century period genre masterpiece hour summary dull anyone cinema running perspective huge series eye seen best director film even rather time say never many br\n",
      "True Label: Positive\n",
      "Predicted Label: Negative\n",
      "Match: False\n",
      "\n",
      "Sample 3:\n",
      "Review: vietnam loaded respective occasionally victoria vincent persona principal explosion wild clean hired advantage shootout feature position force impressive criminal lady support seeing flick opinion taking element small male happens rid two becomes video start help guy town type brother star also bad tv today story cast best action offer real like film movie think still play great michael get show one\n",
      "True Label: Positive\n",
      "Predicted Label: Positive\n",
      "Match: True\n",
      "\n",
      "Sample 4:\n",
      "Review: smell seagal preview influenced whenever fool steven loud speech college thanks factory killed went hope speaking want bunch guy fine anyone could ten write long maybe since star amazing line believe seen work good best look another people like film movie point killer done every come really piece time kill first br one\n",
      "True Label: Negative\n",
      "Predicted Label: Positive\n",
      "Match: False\n",
      "\n",
      "Sample 5:\n",
      "Review: nod source financial president bothered catholic oil marketing distribution committed author cinematographer status essentially origin adaptation stayed society yesterday sexual frost outstanding lengthy moreover energy via understand compare technology depicted said covered editor decision faithful material easily besides process producer office blood bush church discus screenplay animal talking filmmaker kong book benefit whatever iraq writer ride certainly gave expect belongs successful news novel relevant century course seem seemed concern atrocity value political walk oscar contrast subject nothing follow standard video therefore anything regret turn help using king war feel simply could nowhere lot stay reason actually game came better based making country awful made respect felt fit also original doubt leave need performance good case know another new director different people seems offer like film make movie control even play come great written sometimes time get got around audience say many go word thing br exactly right one\n",
      "True Label: Negative\n",
      "Predicted Label: Negative\n",
      "Match: True\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sample_indices = np.random.choice(X_test.shape[0], 5, replace=False)\n",
    "\n",
    "\n",
    "sample_reviews = X_test[sample_indices]\n",
    "sample_true_labels = y_test.iloc[sample_indices]\n",
    "\n",
    "sample_reviews_cleaned = [\" \".join(vectorizer.inverse_transform(sample_reviews[i])[0]) for i in range(sample_reviews.shape[0])]\n",
    "sample_reviews_vectorized = vectorizer.transform(sample_reviews_cleaned)\n",
    "\n",
    "sample_predictions = rfc.predict(sample_reviews_vectorized)\n",
    "\n",
    "for idx, (index, review, true_label, predicted_label) in enumerate(zip(sample_indices, sample_reviews_cleaned, sample_true_labels, sample_predictions)):\n",
    "    print(f\"Sample {idx+1}:\")\n",
    "    print(f\"Review: {review}\")\n",
    "    print(f\"True Label: {'Positive' if true_label == 1 else 'Negative'}\")\n",
    "    print(f\"Predicted Label: {'Positive' if predicted_label == 1 else 'Negative'}\")\n",
    "    print(f\"Match: {true_label == predicted_label}\")\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
